import sys
import click
from typing import Optional, List, Set
from collections import defaultdict
from rich.console import Console

from ..config import Config, PolicyAction
from ..db import Database
from ..github_utils import GitHubClient
from ..git_ops import GitOperations, get_release_commit_range, determine_release_branch_strategy, find_comparison_version
from ..models import SemanticVersion
from ..template_utils import render_template, TemplateError
from ..policies import (
    TicketExtractor,
    CommitConsolidator,
    ReleaseNoteGenerator,
    VersionGapChecker,
    PartialTicketMatch,
    PartialTicketReason
)

console = Console()


def _get_issues_repo(config: Config) -> str:
    """
    Get the issues repository from config.

    Returns the first ticket_repos entry if available, otherwise falls back to code_repo.
    """
    if config.repository.ticket_repos and len(config.repository.ticket_repos) > 0:
        return config.repository.ticket_repos[0]
    return config.repository.code_repo


@click.command(context_settings={'help_option_names': ['-h', '--help']})
@click.argument('version', required=False)
@click.option('--from-version', help='Compare from this version (auto-detected if not specified)')
@click.option('--repo-path', type=click.Path(exists=True), help='Path to local git repository (defaults to synced repo)')
@click.option('--output', '-o', type=click.Path(), help='Output file for release notes')
@click.option('--dry-run', is_flag=True, help='Show what would be generated without creating files')
@click.option('--new', type=click.Choice(['major', 'minor', 'patch', 'rc'], case_sensitive=False), help='Auto-bump version')
@click.option('--detect-mode', type=click.Choice(['all', 'published'], case_sensitive=False), default='published', help='Detection mode for existing releases (default: published)')
@click.option('--format', type=click.Choice(['markdown', 'json'], case_sensitive=False), default='markdown', help='Output format (default: markdown)')
@click.option('--debug', is_flag=True, help='Show detailed pattern matching debug output')
@click.pass_context
def generate(ctx, version: Optional[str], from_version: Optional[str], repo_path: Optional[str],
             output: Optional[str], dry_run: bool, new: Optional[str], detect_mode: str,
             format: str, debug: bool):
    """
    Generate release notes for a version.

    Analyzes commits between versions, consolidates by ticket, and generates
    formatted release notes.

    VERSION can be specified explicitly (e.g., "9.1.0") or auto-calculated using
    --new option. Partial versions are supported (e.g., "9.2" + --new patch creates 9.2.1).

    Examples:

      release-tool generate 9.1.0

      release-tool generate --new minor

      release-tool generate --new rc

      release-tool generate 9.1.0 --dry-run

      release-tool generate --new patch --repo-path /custom/path

      release-tool generate 9.2 --new patch
    """
    if not version and not new:
        console.print("[red]Error: VERSION argument or --new option is required[/red]")
        return

    # Check if version is provided WITH a bump flag (partial version support)
    if version and new:
        # Parse as partial version to use as base
        try:
            base_version = SemanticVersion.parse(version, allow_partial=True)
            console.print(f"[blue]Using base version: {base_version.to_string()}[/blue]")

            # For patch bumps, check if the base version exists first
            # If it doesn't exist, use the base version instead of bumping
            if new == 'patch' and base_version.patch == 0:
                # Need to check if base version exists in Git
                # Load config early to access repo path
                cfg = ctx.obj['config']
                try:
                    git_ops_temp = GitOperations(cfg.get_code_repo_path())
                    existing_versions = git_ops_temp.get_version_tags()
                    base_exists = any(
                        v.major == base_version.major and
                        v.minor == base_version.minor and
                        v.patch == base_version.patch and
                        v.prerelease == base_version.prerelease
                        for v in existing_versions
                    )

                    if not base_exists:
                        # Base version doesn't exist, use it instead of bumping
                        target_version = base_version
                        console.print(f"[blue]Base version {base_version.to_string()} does not exist ‚Üí Creating {target_version.to_string()}[/blue]")
                    else:
                        # Base version exists, bump to next patch
                        target_version = base_version.bump_patch()
                        console.print(f"[blue]Base version {base_version.to_string()} exists ‚Üí Bumping to {target_version.to_string()}[/blue]")
                except Exception as e:
                    # If we can't check, default to bumping
                    console.print(f"[yellow]Warning: Could not check existing versions ({e}), bumping patch[/yellow]")
                    target_version = base_version.bump_patch()
                    console.print(f"[blue]Bumping patch version ‚Üí {target_version.to_string()}[/blue]")
            # Apply the bump for other cases
            elif new == 'major':
                target_version = base_version.bump_major()
                console.print(f"[blue]Bumping major version ‚Üí {target_version.to_string()}[/blue]")
            elif new == 'minor':
                target_version = base_version.bump_minor()
                console.print(f"[blue]Bumping minor version ‚Üí {target_version.to_string()}[/blue]")
            elif new == 'patch':
                # Patch != 0, just bump it
                target_version = base_version.bump_patch()
                console.print(f"[blue]Bumping patch version ‚Üí {target_version.to_string()}[/blue]")
            elif new == 'rc':
                # Check if a final release exists for this base version
                # If yes, bump patch first, then create RC
                # Strategy: Check database FIRST, then optionally check git as fallback
                import re

                cfg = ctx.obj['config']
                final_exists = False
                rc_number = 0
                matching_rcs = []
                checked_db = False
                checked_git = False

                # Step 1: Check database for existing versions (primary source of truth)
                try:
                    db = Database(cfg.database.path)
                    db.connect()

                    repo_name = cfg.repository.code_repo
                    repo = db.get_repository(repo_name)

                    if repo:
                        # Check for final release of this base version
                        final_version_str = f"{base_version.major}.{base_version.minor}.{base_version.patch}"
                        all_releases = db.get_all_releases(
                            repo_id=repo.id,
                            version_prefix=final_version_str
                        )

                        for release in all_releases:
                            # Filter by detect_mode
                            if detect_mode == 'published' and release.is_draft:
                                continue

                            try:
                                v = SemanticVersion.parse(release.version)
                                # Check for exact final version match
                                if (v.major == base_version.major and
                                    v.minor == base_version.minor and
                                    v.patch == base_version.patch and
                                    v.is_final()):
                                    final_exists = True
                                # Also collect RCs while we're here
                                if (v.major == base_version.major and
                                    v.minor == base_version.minor and
                                    v.patch == base_version.patch and
                                    v.prerelease and v.prerelease.startswith('rc.')):
                                    matching_rcs.append(v)
                            except ValueError:
                                continue

                        checked_db = True

                    db.close()
                except Exception as e:
                    console.print(f"[yellow]Warning: Could not check database for existing versions: {e}[/yellow]")

                # Step 2: Optionally check git tags (only if repo exists locally)
                # Only check git if detect_mode is 'all' or if we failed to check DB
                # If detect_mode is 'published', we should rely on DB because git tags don't have draft status
                if (detect_mode == 'all' or not checked_db):
                    try:
                        repo_path = cfg.get_code_repo_path()
                        from pathlib import Path
                        if Path(repo_path).exists():
                            git_ops_temp = GitOperations(repo_path)
                            git_versions = git_ops_temp.get_version_tags()

                            for v in git_versions:
                                # Check for final version
                                if (v.major == base_version.major and
                                    v.minor == base_version.minor and
                                    v.patch == base_version.patch and
                                    v.is_final()):
                                    final_exists = True
                                # Check for RCs
                                if (v.major == base_version.major and
                                    v.minor == base_version.minor and
                                    v.patch == base_version.patch and
                                    v.prerelease and v.prerelease.startswith('rc.')):
                                    if v not in matching_rcs:
                                        matching_rcs.append(v)

                            checked_git = True
                    except Exception as e:
                        # Git check is optional - not a critical failure
                        pass

                # Step 3: Determine target version based on what we found
                if final_exists:
                    # Final release exists - bump patch and create rc.0
                    source = "database" if checked_db else "git" if checked_git else "unknown"
                    console.print(f"[blue]Final release {base_version.to_string()} exists ({source}) ‚Üí Bumping to next patch[/blue]")
                    base_version = base_version.bump_patch()
                    # Reset matching_rcs since we're now working with a new base version
                    matching_rcs = []
                    target_version = base_version.bump_rc(0)
                    console.print(f"[blue]Creating RC version ‚Üí {target_version.to_string()}[/blue]")
                else:
                    # No final release - find existing RCs and auto-increment
                    if matching_rcs:
                        # Extract RC numbers and find the highest
                        rc_numbers = []
                        for v in matching_rcs:
                            match = re.match(r'rc\.(\d+)', v.prerelease)
                            if match:
                                rc_numbers.append(int(match.group(1)))

                        if rc_numbers:
                            rc_number = max(rc_numbers) + 1
                            source = "database" if checked_db else "git" if checked_git else "unknown"
                            console.print(f"[blue]Found existing RCs in {source}, incrementing to rc.{rc_number}[/blue]")
                    elif not checked_db and not checked_git:
                        console.print(f"[yellow]Warning: Could not check existing versions, creating rc.0[/yellow]")

                    target_version = base_version.bump_rc(rc_number)
                    console.print(f"[blue]Creating RC version ‚Üí {target_version.to_string()}[/blue]")

            version = target_version.to_string()
            # Skip the auto-calculation below
            new = None
        except ValueError as e:
            console.print(f"[red]Error parsing version: {e}[/red]")
            return

    config: Config = ctx.obj['config']

    # Determine repo path (use synced repo as default)
    if not repo_path:
        repo_path = config.get_code_repo_path()
        console.print(f"[blue]Using synced repository: {repo_path}[/blue]")

    # Verify repo path exists
    from pathlib import Path
    if not Path(repo_path).exists():
        console.print(f"[red]Error: Repository path does not exist: {repo_path}[/red]")
        if not config.sync.code_repo_path:
            console.print("[yellow]Tip: Run 'release-tool sync' first to clone the repository[/yellow]")
        return

    try:
        # Initialize components
        db = Database(config.database.path)
        db.connect()

        try:
            # Get repository
            repo_name = config.repository.code_repo
            repo = db.get_repository(repo_name)
            if not repo:
                console.print(f"[yellow]Repository {repo_name} not found in database. Running sync...[/yellow]")
                github_client = GitHubClient(config)
                repo = github_client.get_repository_info(repo_name)
                repo.id = db.upsert_repository(repo)
            repo_id = repo.id

            # Initialize Git operations
            git_ops = GitOperations(repo_path)

            # Auto-calculate version if using bump options
            if new:
                # Get all version tags from Git
                all_tags = git_ops.get_version_tags()
                all_tags.sort(reverse=True)
                
                latest_tag = None
                for tag in all_tags:
                    # Check if this tag is a draft in DB if detect_mode is published
                    if detect_mode == 'published':
                        release = db.get_release(repo_id, tag.to_string())
                        if release and release.is_draft:
                            continue
                    
                    # For patch bumps, we only want final versions
                    if new == 'patch' and not tag.is_final():
                        continue
                        
                    latest_tag = tag
                    break

                if not latest_tag:
                    console.print("[red]Error: No suitable tags found in repository. Cannot auto-bump version.[/red]")
                    console.print("[yellow]Tip: Specify version explicitly or create an initial tag[/yellow]")
                    return

                base_version = latest_tag
                console.print(f"[blue]Latest version: {base_version.to_string()}[/blue]")

                if new == 'major':
                    target_version = base_version.bump_major()
                    console.print(f"[blue]Bumping major version ‚Üí {target_version.to_string()}[/blue]")
                elif new == 'minor':
                    target_version = base_version.bump_minor()
                    console.print(f"[blue]Bumping minor version ‚Üí {target_version.to_string()}[/blue]")
                elif new == 'patch':
                    target_version = base_version.bump_patch()
                    console.print(f"[blue]Bumping patch version ‚Üí {target_version.to_string()}[/blue]")
                elif new == 'rc':
                    # Check if base_version is final - if so, bump patch first
                    import re
                    
                    if base_version.is_final():
                        # Base version is final - bump patch and create rc.0
                        console.print(f"[blue]Latest version {base_version.to_string()} is final ‚Üí Bumping to next patch[/blue]")
                        base_version = base_version.bump_patch()
                        target_version = base_version.bump_rc(0)
                        console.print(f"[blue]Creating RC version ‚Üí {target_version.to_string()}[/blue]")
                    else:
                        # Base version is not final - find the next RC number for this version
                        rc_number = 0

                        # Check existing versions for RCs of the same base version
                        matching_rcs = []
                        for v in all_tags:
                            if (v.major == base_version.major and
                                v.minor == base_version.minor and
                                v.patch == base_version.patch and
                                v.prerelease and v.prerelease.startswith('rc.')):
                                
                                if detect_mode == 'published':
                                    release = db.get_release(repo_id, v.to_string())
                                    if release and release.is_draft:
                                        continue
                                matching_rcs.append(v)

                        if matching_rcs:
                            # Extract RC numbers and find the highest
                            rc_numbers = []
                            for v in matching_rcs:
                                match = re.match(r'rc\.(\d+)', v.prerelease)
                                if match:
                                    rc_numbers.append(int(match.group(1)))

                            if rc_numbers:
                                rc_number = max(rc_numbers) + 1

                        target_version = base_version.bump_rc(rc_number)
                        console.print(f"[blue]Creating RC version ‚Üí {target_version.to_string()}[/blue]")

                version = target_version.to_string()
            else:
                # Parse explicitly provided version
                target_version = SemanticVersion.parse(version)

            if dry_run:
                console.print(f"[yellow]DRY RUN: Generating release notes for version {version}[/yellow]")
            else:
                console.print(f"[blue]Generating release notes for version {version}[/blue]")

            # Determine release branch strategy
            available_versions = git_ops.get_version_tags()
            release_branch, source_branch, should_create_branch = determine_release_branch_strategy(
                target_version,
                git_ops,
                available_versions,
                branch_template=config.branch_policy.release_branch_template,
                default_branch=config.branch_policy.default_branch,
                branch_from_previous=config.branch_policy.branch_from_previous_release
            )

            # Display branch information
            console.print(f"[blue]Release branch: {release_branch}[/blue]")
            if should_create_branch:
                console.print(f"[yellow]‚Üí Branch does not exist, will create from: {source_branch}[/yellow]")
            else:
                console.print(f"[blue]‚Üí Using existing branch (source: {source_branch})[/blue]")

            # Create branch if needed (unless dry-run)
            if should_create_branch and config.branch_policy.create_branches:
                if dry_run:
                    console.print(f"[yellow]DRY RUN: Would create branch '{release_branch}' from '{source_branch}'[/yellow]")
                else:
                    try:
                        # Ensure source branch exists locally
                        current_branch = git_ops.get_current_branch()

                        # Create the new release branch
                        git_ops.create_branch(release_branch, source_branch)
                        console.print(f"[green]‚úì Created branch '{release_branch}' from '{source_branch}'[/green]")

                        # Optionally checkout the new branch
                        # git_ops.checkout_branch(release_branch)
                        # console.print(f"[green]‚úì Checked out branch '{release_branch}'[/green]")
                    except ValueError as e:
                        console.print(f"[yellow]Warning: {e}[/yellow]")
                    except Exception as e:
                        console.print(f"[red]Error creating branch: {e}[/red]")
            elif should_create_branch:
                console.print(f"[yellow]‚Üí Branch creation disabled in config[/yellow]")

            # Determine comparison version and get commits
            from_ver = SemanticVersion.parse(from_version) if from_version else None

            if not from_ver:
                # Calculate from_ver respecting detect_mode
                available_versions = git_ops.get_version_tags()
                
                if detect_mode == 'published':
                    # Filter out drafts
                    filtered_versions = []
                    for v in available_versions:
                        release = db.get_release(repo_id, v.to_string())
                        if release and release.is_draft:
                            continue
                        filtered_versions.append(v)
                    available_versions = filtered_versions
                elif detect_mode == 'all':
                    # Add releases from DB that might be missing from local tags
                    # This ensures we detect previous RCs even if tags aren't fetched yet
                    try:
                        db_releases = db.get_all_releases(repo_id)
                        for release in db_releases:
                            try:
                                v = SemanticVersion.parse(release.version)
                                if v not in available_versions:
                                    available_versions.append(v)
                            except ValueError:
                                continue
                        available_versions.sort()
                    except Exception as e:
                        console.print(f"[yellow]Warning: Could not fetch releases from DB: {e}[/yellow]")
                
                from_ver = find_comparison_version(target_version, available_versions)

            # Determine head_ref for commit range
            # If we are creating a new branch, the head is the source branch
            # If we are using an existing branch, the head is that branch
            if should_create_branch:
                head_ref = source_branch
            else:
                head_ref = release_branch
                
            # If the branch exists remotely but not locally, we might need to prefix with origin/
            # However, git_ops usually handles local branches. 
            # If we are in dry-run and the branch exists only on remote, we should use origin/branch
            if not should_create_branch and not git_ops.branch_exists(head_ref) and git_ops.branch_exists(head_ref, remote=True):
                head_ref = f"origin/{head_ref}"

            comparison_version, commits = get_release_commit_range(
                git_ops,
                target_version,
                from_ver,
                head_ref=head_ref
            )

            if comparison_version:
                console.print(f"[blue]Comparing {comparison_version.to_string()} ‚Üí {version}[/blue]")

                # Check for version gaps
                gap_checker = VersionGapChecker(config)
                gap_checker.check_gap(comparison_version.to_string(), version)
            else:
                console.print(f"[blue]Generating notes for all commits up to {version}[/blue]")

            console.print(f"[blue]Found {len(commits)} commits[/blue]")

            # Convert git commits to our models and store them
            commit_models = []
            for git_commit in commits:
                commit_model = git_ops.commit_to_model(git_commit, repo_id)
                db.upsert_commit(commit_model)
                commit_models.append(commit_model)

            # Build PR map
            pr_map = {}
            for commit in commit_models:
                if commit.pr_number:
                    pr = db.get_pull_request(repo_id, commit.pr_number)
                    if pr:
                        pr_map[commit.pr_number] = pr

            # Extract tickets and consolidate
            extractor = TicketExtractor(config, debug=debug)
            consolidator = CommitConsolidator(config, extractor, debug=debug)
            consolidated_changes = consolidator.consolidate(commit_models, pr_map)

            console.print(f"[blue]Consolidated into {len(consolidated_changes)} changes[/blue]")

            # Handle missing tickets
            consolidator.handle_missing_tickets(consolidated_changes)

            # Load ticket information from database (offline) with partial detection
            # Tickets must be synced first using: release-tool sync
            partial_matches: List[PartialTicketMatch] = []
            resolved_ticket_keys: Set[str] = set()  # Track successfully resolved tickets

            # Get expected ticket repository IDs
            expected_repos = config.get_ticket_repos()
            expected_repo_ids = []
            for ticket_repo_name in expected_repos:
                repo = db.get_repository(ticket_repo_name)
                if repo:
                    expected_repo_ids.append(repo.id)

            for change in consolidated_changes:
                if change.ticket_key:
                    # Query ticket from database across all repos
                    ticket = db.get_ticket_by_key(change.ticket_key)

                    if not ticket:
                        # NOT FOUND - create partial match
                        extraction_source = _get_extraction_source(change)
                        partial = PartialTicketMatch(
                            ticket_key=change.ticket_key,
                            extracted_from=extraction_source,
                            match_type="not_found",
                            potential_reasons={
                                PartialTicketReason.OLDER_THAN_CUTOFF,
                                PartialTicketReason.TYPO,
                                PartialTicketReason.SYNC_NOT_RUN
                            }
                        )
                        partial_matches.append(partial)

                        if debug:
                            console.print(f"\n[yellow]‚ö†Ô∏è  Ticket {change.ticket_key} not found in DB[/yellow]")

                    elif ticket.repo_id not in expected_repo_ids:
                        # DIFFERENT REPO - create partial match
                        found_repo = db.get_repository_by_id(ticket.repo_id)
                        extraction_source = _get_extraction_source(change)
                        partial = PartialTicketMatch(
                            ticket_key=change.ticket_key,
                            extracted_from=extraction_source,
                            match_type="different_repo",
                            found_in_repo=found_repo.full_name if found_repo else "unknown",
                            ticket_url=ticket.url,
                            potential_reasons={
                                PartialTicketReason.REPO_CONFIG_MISMATCH,
                                PartialTicketReason.WRONG_TICKET_REPOS
                            }
                        )
                        partial_matches.append(partial)

                        if debug:
                            console.print(f"\n[yellow]‚ö†Ô∏è  Ticket {change.ticket_key} in different repo: {found_repo.full_name if found_repo else 'unknown'}[/yellow]")

                    else:
                        # Found in correct repo - mark as resolved
                        resolved_ticket_keys.add(change.ticket_key)
                        if debug:
                            console.print(f"\n[dim]üìã Found ticket in DB: #{ticket.number} - {ticket.title}[/dim]")

                    change.ticket = ticket

            # Apply partial ticket policy (with resolved/unresolved tracking)
            _handle_partial_tickets(partial_matches, resolved_ticket_keys, config, debug)

            # Check for inter-release duplicate tickets
            consolidated_changes = _check_inter_release_duplicates(
                consolidated_changes,
                target_version,
                db,
                repo_id,
                config,
                debug
            )

            # Generate release notes
            note_generator = ReleaseNoteGenerator(config)
            release_notes = []
            for change in consolidated_changes:
                note = note_generator.create_release_note(change, change.ticket)
                release_notes.append(note)

            # Group and format
            grouped_notes = note_generator.group_by_category(release_notes)

            # Format output based on format option
            if format == 'json':
                import json
                # Convert to JSON
                json_output = {
                    'version': version,
                    'from_version': comparison_version.to_string() if comparison_version else None,
                    'num_commits': len(commits),
                    'num_changes': len(consolidated_changes),
                    'categories': {}
                }
                for category, notes in grouped_notes.items():
                    json_output['categories'][category] = [
                        {
                            'title': note.title,
                            'ticket_key': note.ticket_key,
                            'description': note.description,
                            'labels': note.labels
                        }
                        for note in notes
                    ]
                formatted_output = json.dumps(json_output, indent=2)
                doc_formatted_output = None
            else:
                # Determine release_output_path and doc_output_path
                release_output_path = output
                doc_output_path = None

                # If no explicit output provided, use config templates
                if not release_output_path:
                    # Build default draft path from config template
                    template_context = {
                        'code_repo': repo_name.replace('/', '-'),  # Sanitized for filesystem
                        'issue_repo': _get_issues_repo(config),    # First ticket_repos or code_repo
                        'version': version,
                        'major': str(target_version.major),
                        'minor': str(target_version.minor),
                        'patch': str(target_version.patch),
                        'output_file_type': 'release'
                    }
                    try:
                        release_output_path = render_template(config.output.draft_output_path, template_context)
                    except TemplateError as e:
                        console.print(f"[red]Error rendering draft_output_path template: {e}[/red]")
                        sys.exit(1)

                    # Compute doc_output_path if configured (as a draft)
                    if config.output.doc_output_path and config.release_notes.doc_output_template:
                        # Use draft_output_path for doc draft as well, but with type='doc'
                        template_context['output_file_type'] = 'doc'
                        try:
                            doc_output_path = render_template(config.output.draft_output_path, template_context)
                        except TemplateError as e:
                            console.print(f"[red]Error rendering draft_output_path template for docs: {e}[/red]")
                            sys.exit(1)
                
                # If explicit output provided, we use that for release notes.
                # For docs, we use the configured doc_output_path (final path) as fallback?
                # Or we skip doc generation?
                # The previous behavior was to generate docs to doc_output_path.
                elif config.output.doc_output_path and config.release_notes.doc_output_template:
                    template_context = {
                        'code_repo': repo_name.replace('/', '-'),
                        'issue_repo': _get_issues_repo(config),
                        'version': version,
                        'major': str(target_version.major),
                        'minor': str(target_version.minor),
                        'patch': str(target_version.patch),
                        'output_file_type': 'doc'
                    }
                    try:
                        doc_output_path = render_template(config.output.doc_output_path, template_context)
                    except TemplateError as e:
                        console.print(f"[red]Error rendering doc_output_path template: {e}[/red]")
                        sys.exit(1)

                # Format markdown with media processing
                result = note_generator.format_markdown(
                    grouped_notes,
                    version,
                    release_output_path=release_output_path,
                    doc_output_path=doc_output_path
                )

                # Handle return value (tuple or single string)
                if isinstance(result, tuple):
                    formatted_output, doc_formatted_output = result
                else:
                    formatted_output = result
                    doc_formatted_output = None

            # Output handling
            if dry_run:
                console.print(f"\n[yellow]{'='*80}[/yellow]")
                console.print(f"[yellow]DRY RUN - Release notes for {version}:[/yellow]")
                console.print(f"[yellow]{'='*80}[/yellow]\n")
                console.print(formatted_output)
                console.print(f"\n[yellow]{'='*80}[/yellow]")
                if doc_formatted_output:
                    console.print(f"\n[bold]Documentation Release Notes Output:[/bold]")
                    console.print(f"[dim]{'‚îÄ' * 60}[/dim]")
                    console.print(doc_formatted_output)
                    console.print(f"[dim]{'‚îÄ' * 60}[/dim]")
                console.print(f"[yellow]{'='*80}[/yellow]\n")
                console.print(f"[yellow]DRY RUN complete. No files were created.[/yellow]")
            else:
                # Write release notes file
                release_path_obj = Path(release_output_path)
                release_path_obj.parent.mkdir(parents=True, exist_ok=True)
                release_path_obj.write_text(formatted_output)
                console.print(f"[green]‚úì Release notes written to:[/green]")
                console.print(f"[green]  {release_path_obj.absolute()}[/green]")

                # Write doc output file if configured
                if doc_formatted_output and doc_output_path:
                    doc_path_obj = Path(doc_output_path)
                    doc_path_obj.parent.mkdir(parents=True, exist_ok=True)
                    doc_path_obj.write_text(doc_formatted_output)
                    console.print(f"[green]‚úì Docusaurus release notes written to:[/green]")
                    console.print(f"[green]  {doc_path_obj.absolute()}[/green]")

                console.print(f"[blue]‚Üí Review and edit the files, then use 'release-tool publish {version} -f {release_output_path}' to upload to GitHub[/blue]")

        finally:
            db.close()

    except Exception as e:
        console.print(f"[red]Error: {e}[/red]")
        if '--debug' in sys.argv:
            raise
        sys.exit(1)


def _get_extraction_source(change, commits_map=None, prs_map=None):
    """
    Get human-readable description of where a ticket was extracted from.

    Args:
        change: ConsolidatedChange object
        commits_map: Optional dict mapping sha to commit for lookups
        prs_map: Optional dict mapping pr_number to PR for lookups

    Returns:
        String like "branch feat/meta-8624/main, pattern #1"
    """
    # Try to get from PR first (most reliable)
    if change.prs and len(change.prs) > 0:
        pr = change.prs[0]
        if pr.head_branch:
            return f"branch {pr.head_branch}, PR #{pr.number}"
        return f"PR #{pr.number}"

    # Fall back to commit info
    if change.commits and len(change.commits) > 0:
        commit = change.commits[0]
        return f"commit {commit.sha[:7]}"

    return "unknown source"


def _extract_ticket_keys_from_release_notes(release_body: str) -> Set[str]:
    """
    Extract ticket keys from release notes body.

    Args:
        release_body: The markdown body of release notes

    Returns:
        Set of ticket keys found in the release notes
    """
    import re
    ticket_keys = set()

    # Pattern 1: #1234 format
    for match in re.finditer(r'#(\d+)', release_body):
        ticket_keys.add(match.group(1))

    # Pattern 2: owner/repo#1234 format
    for match in re.finditer(r'[\w-]+/[\w-]+#(\d+)', release_body):
        ticket_keys.add(match.group(1))

    return ticket_keys


def _check_inter_release_duplicates(
    consolidated_changes: List,
    target_version: SemanticVersion,
    db: Database,
    repo_id: int,
    config,
    debug: bool
) -> List:
    """
    Check for tickets that appear in earlier releases and apply deduplication policy.

    Args:
        consolidated_changes: List of consolidated changes with tickets
        target_version: The version being generated
        db: Database instance
        repo_id: Repository ID
        config: Config with inter_release_duplicate_action policy
        debug: Debug mode flag

    Returns:
        Filtered list of consolidated changes (with duplicates removed if policy is IGNORE)
    """
    from ..models import SemanticVersion

    action = config.ticket_policy.inter_release_duplicate_action

    if action == PolicyAction.IGNORE and not debug:
        # Skip the check entirely if ignoring and not debugging
        pass

    # Get all earlier releases (semantically before target version)
    all_releases = db.get_all_releases(repo_id=repo_id, limit=None)

    earlier_releases = []
    for release in all_releases:
        try:
            release_version = SemanticVersion.parse(release.version)
            if release_version < target_version:
                earlier_releases.append(release)
        except ValueError:
            # Skip releases with invalid version strings
            continue

    if not earlier_releases:
        # No earlier releases to check against
        return consolidated_changes

    # Extract ticket keys from all earlier releases
    tickets_in_earlier_releases = {}  # ticket_key -> list of (version, release)
    for release in earlier_releases:
        if release.body:
            ticket_keys = _extract_ticket_keys_from_release_notes(release.body)
            for ticket_key in ticket_keys:
                if ticket_key not in tickets_in_earlier_releases:
                    tickets_in_earlier_releases[ticket_key] = []
                tickets_in_earlier_releases[ticket_key].append((release.version, release))

    # Check current changes against earlier releases
    duplicate_tickets = {}  # ticket_key -> list of versions
    for change in consolidated_changes:
        if change.ticket_key and change.ticket_key in tickets_in_earlier_releases:
            versions = [v for v, r in tickets_in_earlier_releases[change.ticket_key]]
            duplicate_tickets[change.ticket_key] = versions

    if not duplicate_tickets:
        # No duplicates found
        return consolidated_changes

    # Apply policy
    if action == PolicyAction.IGNORE:
        # Filter out duplicate tickets from consolidated_changes
        filtered_changes = [
            change for change in consolidated_changes
            if not (change.ticket_key and change.ticket_key in duplicate_tickets)
        ]

        if debug:
            console.print(f"\n[dim]Filtered out {len(duplicate_tickets)} duplicate ticket(s) found in earlier releases:[/dim]")
            for ticket_key, versions in duplicate_tickets.items():
                console.print(f"  [dim]‚Ä¢ #{ticket_key} (in releases: {', '.join(versions)})[/dim]")

        return filtered_changes

    elif action == PolicyAction.WARN:
        # Include duplicates but warn
        msg_lines = []
        msg_lines.append("")
        msg_lines.append(f"[yellow]‚ö†Ô∏è  Warning: Found {len(duplicate_tickets)} ticket(s) that appear in earlier releases:[/yellow]")
        for ticket_key, versions in duplicate_tickets.items():
            msg_lines.append(f"  ‚Ä¢ [bold]#{ticket_key}[/bold] (in releases: {', '.join(versions)})")
        msg_lines.append("")
        msg_lines.append("[dim]These tickets will be included in this release but also exist in earlier releases.[/dim]")
        msg_lines.append("[dim]To exclude duplicates, set ticket_policy.inter_release_duplicate_action = 'ignore'[/dim]")
        msg_lines.append("")
        console.print("\n".join(msg_lines))

        return consolidated_changes

    elif action == PolicyAction.ERROR:
        # Fail with error
        msg_lines = []
        msg_lines.append(f"[red]Error: Found {len(duplicate_tickets)} ticket(s) that appear in earlier releases:[/red]")
        for ticket_key, versions in duplicate_tickets.items():
            msg_lines.append(f"  ‚Ä¢ [bold]#{ticket_key}[/bold] (in releases: {', '.join(versions)})")
        console.print("\n".join(msg_lines))
        raise RuntimeError(f"Inter-release duplicate tickets found ({len(duplicate_tickets)} total). Policy: error")

    return consolidated_changes


def _display_partial_section(partials: List[PartialTicketMatch], section_title: str) -> List[str]:
    """
    Helper function to display a section of partial tickets with details.

    Args:
        partials: List of PartialTicketMatch objects to display
        section_title: Title for this section

    Returns:
        List of formatted message lines
    """
    msg_lines = []

    if not partials:
        return msg_lines

    # Group by type
    not_found = [p for p in partials if p.match_type == "not_found"]
    different_repo = [p for p in partials if p.match_type == "different_repo"]

    msg_lines.append(f"[cyan]{section_title}:[/cyan]")
    msg_lines.append("")

    # Handle different_repo partials
    if different_repo:
        msg_lines.append(f"[yellow]Tickets in different repository ({len(different_repo)}):[/yellow]")

        # Group tickets by reason
        tickets_by_reason = defaultdict(list)
        for p in different_repo:
            for reason in p.potential_reasons:
                tickets_by_reason[reason].append(p)

        # Show reasons with associated tickets
        msg_lines.append(f"  [dim]This might be because of:[/dim]")
        for reason, tickets in tickets_by_reason.items():
            ticket_keys = [p.ticket_key for p in tickets]
            msg_lines.append(f"    ‚Ä¢ {reason.description}")
            msg_lines.append(f"      [dim]Tickets:[/dim] {', '.join(ticket_keys)}")

        msg_lines.append("")
        msg_lines.append("  [dim]Details:[/dim]")
        for p in different_repo:
            msg_lines.append(f"    ‚Ä¢ [bold]{p.ticket_key}[/bold] (from {p.extracted_from})")
            if p.found_in_repo:
                msg_lines.append(f"      [dim]Found in:[/dim] {p.found_in_repo}")
            if p.ticket_url:
                msg_lines.append(f"      [dim]URL:[/dim] {p.ticket_url}")
        msg_lines.append("")

    # Handle not_found partials
    if not_found:
        msg_lines.append(f"[yellow]Tickets not found in database ({len(not_found)}):[/yellow]")

        # Group tickets by reason
        tickets_by_reason = defaultdict(list)
        for p in not_found:
            for reason in p.potential_reasons:
                tickets_by_reason[reason].append(p)

        # Show reasons with associated tickets
        msg_lines.append(f"  [dim]This might be because of:[/dim]")
        for reason, tickets in tickets_by_reason.items():
            ticket_keys = [p.ticket_key for p in tickets]
            msg_lines.append(f"    ‚Ä¢ {reason.description}")
            msg_lines.append(f"      [dim]Tickets:[/dim] {', '.join(ticket_keys)}")

        msg_lines.append("")
        msg_lines.append("  [dim]Details:[/dim]")
        for p in not_found:
            msg_lines.append(f"    ‚Ä¢ [bold]{p.ticket_key}[/bold] (from {p.extracted_from})")
        msg_lines.append("")

    return msg_lines


def _handle_partial_tickets(
    all_partials: List[PartialTicketMatch],
    resolved_ticket_keys: Set[str],
    config,
    debug: bool
):
    """
    Handle partial ticket matches based on policy configuration.

    Args:
        all_partials: List of ALL PartialTicketMatch objects (resolved and unresolved)
        resolved_ticket_keys: Set of ticket keys that were eventually resolved
        config: Config object with ticket_policy.partial_ticket_action
        debug: Whether debug mode is enabled

    Raises:
        RuntimeError: If policy is ERROR and unresolved partials exist
    """
    if not all_partials:
        return

    action = config.ticket_policy.partial_ticket_action

    if action == PolicyAction.IGNORE:
        return

    # Split into resolved and unresolved
    unresolved_partials = [p for p in all_partials if p.ticket_key not in resolved_ticket_keys]
    resolved_partials = [p for p in all_partials if p.ticket_key in resolved_ticket_keys]

    # DEBUG MODE: Show both resolved and unresolved with full details
    if debug:
        msg_lines = []
        msg_lines.append("")

        # Header with counts
        if unresolved_partials and resolved_partials:
            msg_lines.append(f"[yellow]‚ö†Ô∏è  Found {len(unresolved_partials)} unresolved and {len(resolved_partials)} resolved partial ticket match(es)[/yellow]")
        elif unresolved_partials:
            msg_lines.append(f"[yellow]‚ö†Ô∏è  Found {len(unresolved_partials)} unresolved partial ticket match(es)[/yellow]")
        else:
            msg_lines.append(f"[green]‚úì {len(resolved_partials)} partial ticket match(es) were fully resolved[/green]")
        msg_lines.append("")

        # Show unresolved section first (if any)
        if unresolved_partials:
            unresolved_section = _display_partial_section(unresolved_partials, "Unresolved Partial Matches")
            msg_lines.extend(unresolved_section)

        # Show resolved section (if any)
        if resolved_partials:
            resolved_section = _display_partial_section(resolved_partials, "Resolved Partial Matches")
            msg_lines.extend(resolved_section)

        # Add resolution tips for unresolved
        if unresolved_partials:
            msg_lines.append("[dim]To resolve:[/dim]")
            msg_lines.append("  1. Run [bold]'release-tool sync'[/bold] to fetch latest tickets")
            msg_lines.append("  2. Check [bold]repository.ticket_repos[/bold] in config")
            msg_lines.append("  3. Verify ticket numbers in branches/PRs")
            msg_lines.append("")

        console.print("\n".join(msg_lines))

    # WARN MODE: Brief message if all resolved, full details if any unresolved
    elif action == PolicyAction.WARN:
        if not unresolved_partials:
            # All resolved - brief message only
            console.print(f"[dim]‚ÑπÔ∏è  {len(resolved_partials)} partial ticket match(es) were fully resolved. Use --debug for details.[/dim]")
        else:
            # Has unresolved - show full details for unresolved only
            msg_lines = []
            msg_lines.append("")
            msg_lines.append(f"[yellow]‚ö†Ô∏è  Warning: Found {len(unresolved_partials)} unresolved partial ticket match(es)[/yellow]")
            if resolved_partials:
                msg_lines.append(f"[dim]({len(resolved_partials)} were resolved)[/dim]")
            msg_lines.append("")

            # Show unresolved details
            unresolved_section = _display_partial_section(unresolved_partials, "Unresolved Partial Matches")
            msg_lines.extend(unresolved_section)

            # Add resolution tips
            msg_lines.append("[dim]To resolve:[/dim]")
            msg_lines.append("  1. Run [bold]'release-tool sync'[/bold] to fetch latest tickets")
            msg_lines.append("  2. Check [bold]repository.ticket_repos[/bold] in config")
            msg_lines.append("  3. Verify ticket numbers in branches/PRs")
            msg_lines.append("")

            console.print("\n".join(msg_lines))

    # ERROR MODE: Fail if any unresolved
    if action == PolicyAction.ERROR and unresolved_partials:
        raise RuntimeError(f"Unresolved partial ticket matches found ({len(unresolved_partials)} total). Policy: error")
